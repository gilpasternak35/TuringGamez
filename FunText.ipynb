{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "import pandas as pd\n",
    "import requests, sys, webbrowser,xml\n",
    "import numpy as np\n",
    "import bs4\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline usage to perform test generation, using the hugging face package transformers. Citation is below:\n",
    "@article{Wolf2019HuggingFacesTS,\n",
    "  title={HuggingFace's Transformers: State-of-the-art Natural Language Processing},\n",
    "  author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and R'emi Louf and Morgan Funtowicz and Jamie Brew},\n",
    "  journal={ArXiv},\n",
    "  year={2019},\n",
    "  volume={abs/1910.03771}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting up pipeline\n",
    "def startPipeline():\n",
    "    generator = pipeline('fill-mask', model='bert-base-uncased')\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gilpasternak/opt/miniconda3/lib/python3.7/site-packages/transformers/modeling_auto.py:798: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  FutureWarning,\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['cls.predictions.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "nlp = startPipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Given a number letters and some sequence, returns the sequence with generated attached words\n",
    "def generateText(generator,intro_sequence:str, num_words = 5)->str:\n",
    "    # Imported random text generation\n",
    "    text = generator(intro_sequence, max_length=len(intro_sequence) + num_words, num_return_sequences=1)[0].get(\"generated_text\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getText(url = \"https://www.keepinspiring.me/famous-quotes/\" ):\n",
    "    # Requesting data from url, finding specialized tags for this particular website\n",
    "    res = requests.get(url)\n",
    "    res.raise_for_status()\n",
    "    soup = bs4.BeautifulSoup(res.text, \"html.parser\")\n",
    "    text  = soup.find_all(\"div\", class_ = 'author-quotes')  \n",
    "    return text\n",
    "text = getText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Game List: \n",
    "1) **Mad Libs** \n",
    "\n",
    "2) **Find the real quote**\n",
    "\n",
    "3) **How well do you know your favorite song?**\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Processing Below\n",
    "Scraping the data from our quote website and cleaning it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtainin author from quote\n",
    "def authors(quote):\n",
    "    return quote.split(\"”\")[1]\n",
    "\n",
    "#Removing author and adding lost smartquote\n",
    "def removeAuthors(quote):\n",
    "    return (quote.split(\"”\")[0] + (\"”\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tag processing functions to clean up nasty html formatting, replaces div tags\n",
    "def processing_div(tag):\n",
    "    return tag.replace('<div class=\"author-quotes\">', \"\").replace(\"</div>\", \"\")\n",
    "\n",
    "#span processing, replaces span tag\n",
    "def processing_span(tag):\n",
    "    return tag.replace(\"<span class=\\\"quote-author-name\\\">\", \"\").replace(\"</span>\", \"\")\n",
    "\n",
    "# Checks for tags that have yet to be removed, not given standard format. Reasoning - we don't know when ads will pop up\n",
    "def cleaner(table):\n",
    "    arr = np.array([])\n",
    "    for i in table.get(\"quote\"):\n",
    "        arr = np.append(arr,(\"<\" in i))\n",
    "    clean = table[(arr != 1)]\n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quote</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“You know you’re in love when you can’t fall a...</td>\n",
       "      <td>– Dr. Suess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“I’m selfish, impatient and a little insecure....</td>\n",
       "      <td>– Marilyn Monroe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“Get busy living or get busy dying.”</td>\n",
       "      <td>– Stephen King</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“The first step toward success is taken when y...</td>\n",
       "      <td>– Mark Caine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>“Twenty years from now you will be more disapp...</td>\n",
       "      <td>– Mark Twain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>“The dream crossed twilight between birth and ...</td>\n",
       "      <td>– T. S. Eliot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>“Don’t think. Thinking is the enemy of creativ...</td>\n",
       "      <td>– Ray Bradbury</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>“The power of imagination makes us infinite.”</td>\n",
       "      <td>– John Muir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>“Originality is nothing but judicious imitation.”</td>\n",
       "      <td>– Voltaire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>“Life is made of ever so many partings welded ...</td>\n",
       "      <td>– Charles Dickens</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                quote              author\n",
       "0   “You know you’re in love when you can’t fall a...         – Dr. Suess\n",
       "1   “I’m selfish, impatient and a little insecure....    – Marilyn Monroe\n",
       "2                “Get busy living or get busy dying.”      – Stephen King\n",
       "3   “The first step toward success is taken when y...        – Mark Caine\n",
       "5   “Twenty years from now you will be more disapp...        – Mark Twain\n",
       "..                                                ...                 ...\n",
       "83  “The dream crossed twilight between birth and ...       – T. S. Eliot\n",
       "84  “Don’t think. Thinking is the enemy of creativ...      – Ray Bradbury\n",
       "86      “The power of imagination makes us infinite.”         – John Muir\n",
       "88  “Originality is nothing but judicious imitation.”          – Voltaire\n",
       "89  “Life is made of ever so many partings welded ...   – Charles Dickens\n",
       "\n",
       "[72 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame().assign(quote = text)\n",
    "\n",
    "#Formatting, processing, and splitting quotes and authors\n",
    "def tableProcess(table):\n",
    "    table = table.assign(quote = table.get(\"quote\").apply(str))\n",
    "    table = table.assign(quote = table.get(\"quote\").apply(processing_div).apply(processing_span))\n",
    "    table = cleaner(table)\n",
    "    table = table.assign(author  = table.get(\"quote\").apply(authors), quote = table.get(\"quote\").apply(removeAuthors))\n",
    "    return table\n",
    "table = tableProcess(table)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Word Replacement to be used in each individual Turing game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_words_at_random(generator, word_arr: [str], num_words: int, difficulty = 1):\n",
    "    \n",
    "    #  Generate num_words random indices\n",
    "    indices = randomGeneration(num_words, 0, len(word_arr))\n",
    "    print(indices)\n",
    "    \n",
    "    # Place word masks at each of the randomly chosen indices\n",
    "    # Fill in each mask with the language model\n",
    "    for i in indices:\n",
    "        #Ensuring array is not overaccessed\n",
    "        if(i < len(word_arr)):\n",
    "            word_arr[i] = '[MASK]'\n",
    "        \n",
    "        #Adding together everything leading up to string so as to add some context into the model\n",
    "        join  = \" \".join(word_arr)\n",
    "\n",
    "        # Generate the next word\n",
    "        text = (generator(join)[3-difficulty].get('sequence').replace(\"[CLS]\", '').replace('[SEP]', '')).strip()\n",
    "        word_arr = text.split(\" \")\n",
    "\n",
    "    return text, indices \n",
    "\n",
    "# Generates a desired number of unique random digits in a certain range\n",
    "def randomGeneration(num_words, lowNum, highNum):\n",
    "    random_digits = np.unique(np.random.randint(low = lowNum, high  = highNum, size = num_words))\n",
    "    while(len(random_digits) < num_words):\n",
    "        random_digits = np.append(random_digits, np.random.randint(low = lowNum, high = highNum, size = num_words-len(random_digits)))\n",
    "        random_digits = np.unique(random_digits)\n",
    "    return random_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Search Below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start at user given wikipedia page, randomly click a certain number of links from there and scrape 5 sentences from the final page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtains text from a wikipedia url\n",
    "def getWikiText(url):\n",
    "    # Requesting data from url, finding specialized tags for this particular website\n",
    "    res = requests.get(url)\n",
    "    res.raise_for_status()\n",
    "    \n",
    "    #Attaching soup object to page text, obtaining text in paragraphs\n",
    "    soup = bs4.BeautifulSoup(res.text, \"lxml\")\n",
    "    text = \"\"\n",
    "    \n",
    "    # Problematic structure: fails to look for list items which make up substantial amount of wikipedia pages\n",
    "    for paragraph in soup.find_all('p'):\n",
    "        text+= paragraph.text\n",
    "        \n",
    "    # Formatting the string so that it looks normal\n",
    "    text = re.sub(r'\\[.*\\]', '', text)\n",
    "    text= re.sub(r'\\s+', ' ', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterates through wikipedia pages\n",
    "def wiki_search():\n",
    "    topic, pages = inp()\n",
    "    textSoup, title = looping_wiki_search(topic, int(pages))\n",
    "    return textSoup, title \n",
    "\n",
    "# Randomly selecting the next topic to be searched for\n",
    "def selectNextTopic(text: [str])-> str:\n",
    "    random_number = np.random.randint(1,len(text))\n",
    "    return text[random_number]\n",
    "\n",
    "# Replaces hyphens with an underscore for url purposes, removes all punctuation that could break url\n",
    "def replacePunctuation(text):\n",
    "    specific_case = text.strip()\n",
    "    specific_case = specific_case.replace('-',' ')\n",
    "    specific_case = specific_case.replace(' ', '_')\n",
    "    \n",
    "    # Remove all punctuation\n",
    "    pattern = re.compile(r'\\W')\n",
    "    specific_case = re.sub(pattern, '', specific_case)\n",
    "    \n",
    "    return specific_case\n",
    "    \n",
    "    \n",
    "# Loop through connected topics on wikipedia to find a \"landing page\", then return the text of that landing page\n",
    "def looping_wiki_search(topic, neighbor_pages):\n",
    "    searchText = \"\"\n",
    "    url = construct_wiki_url(topic)\n",
    "    for i in np.arange(neighbor_pages+1):\n",
    "        print(i)\n",
    "        searchText = getWikiText(url).split(\" \")\n",
    "        \n",
    "        \n",
    "        #So long as there are still pages left to proccess\n",
    "        if(i < neighbor_pages):\n",
    "            \n",
    "            # Selecting next topic\n",
    "            topic = selectNextTopic(searchText)\n",
    "\n",
    "            # Replacing the punctuation of the next topic\n",
    "            topic = replacePunctuation(topic)\n",
    "\n",
    "            # Moving to next URL\n",
    "            url = construct_wiki_url(topic)\n",
    "        \n",
    "    return searchText, topic\n",
    "        \n",
    "\n",
    "# Temporary dummy input\n",
    "def inp():\n",
    "    print(\"Please enter a topic\")\n",
    "    val = str(input())\n",
    "    print('Please enter the number of neighbor pages: ')\n",
    "    pages = input()\n",
    "    return val, pages\n",
    "\n",
    "# Takes a given user topic and constructs a valid wikipedia url\n",
    "def construct_wiki_url(url_topic : str):\n",
    "    return ('https://en.wikipedia.org/wiki/' + url_topic.lower().strip().replace(\" \",\"_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter a topic\n",
      "may\n",
      "Please enter the number of neighbor pages: \n",
      "8\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['producer', 'or', 'producers', 'may', 'refer', 'to:', ''], 'produced')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last Scrape for Song Game: Scraping Genius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lyricsgenius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes artist and song name in terms of string and obtains lyrics\n",
    "def obtainLyrics(artist: str, song: str):\n",
    "    genius = lyricsgenius.Genius(\"NDltUrlbSis8n9o1FEyGUE_ruIlngdDmXwoQdvrkX0hh3le3LKF8XalcHXOetm3x\")\n",
    "    artist = genius.search_artist(artist, max_songs=3, sort=\"title\")\n",
    "    song = genius.search_song(song, artist.name)\n",
    "    song_lyrics =  song.lyrics\n",
    "    \n",
    "    #String proccessing\n",
    "    song_lyrics = re.sub(r'\\[.*\\]', '', song_lyrics)\n",
    "    song_lyrics  = re.sub(r'\\n+', ' ', song_lyrics)\n",
    "    song_lyrics = song_lyrics.split(\" \")\n",
    "    \n",
    "    #Making sure songs do not exceed maximum threshold\n",
    "    if(len(song_lyrics) > 510):\n",
    "        song_lyrics = song_lyrics[:510]\n",
    "    return song_lyrics\n",
    "\n",
    "# Master Controls obtaining and proccessing lyrics\n",
    "# To do: preserve tags, ie [verse 1], and keep word replacement model from touching it \n",
    "def lyrics(artistName, songName):\n",
    "    lyrics = obtainLyrics(artistName, songName) \n",
    "    return lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for songs by Toto...\n",
      "\n",
      "Song 1: \"21st Century Blues\"\n",
      "Song 2: \"2 Hearts\"\n",
      "Song 3: \"99\"\n",
      "\n",
      "Reached user-specified song limit (3).\n",
      "Done. Found 3 songs.\n",
      "Searching for \"Africa\" by Toto...\n",
      "Done.\n",
      "1349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'I',\n",
       " 'hear',\n",
       " 'the',\n",
       " 'drums',\n",
       " 'echoing',\n",
       " 'tonight',\n",
       " 'But',\n",
       " 'she',\n",
       " 'hears',\n",
       " 'only',\n",
       " 'whispers',\n",
       " 'of',\n",
       " 'some',\n",
       " 'quiet',\n",
       " 'conversation',\n",
       " \"She's\",\n",
       " 'coming',\n",
       " 'in,',\n",
       " '12:30',\n",
       " 'flight',\n",
       " 'Her',\n",
       " 'moonlit',\n",
       " 'wings',\n",
       " 'reflect',\n",
       " 'the',\n",
       " 'stars',\n",
       " 'that',\n",
       " 'guide',\n",
       " 'me',\n",
       " 'towards',\n",
       " 'salvation',\n",
       " 'I',\n",
       " 'stopped',\n",
       " 'an',\n",
       " 'old',\n",
       " 'man',\n",
       " 'along',\n",
       " 'the',\n",
       " 'way',\n",
       " 'Hoping',\n",
       " 'to',\n",
       " 'find',\n",
       " 'some',\n",
       " 'old',\n",
       " 'forgotten',\n",
       " 'words',\n",
       " 'or',\n",
       " 'ancient',\n",
       " 'melodies',\n",
       " 'He',\n",
       " 'turned',\n",
       " 'to',\n",
       " 'me',\n",
       " 'as',\n",
       " 'if',\n",
       " 'to',\n",
       " 'say',\n",
       " '\"Hurry',\n",
       " 'boy,',\n",
       " \"it's\",\n",
       " 'waiting',\n",
       " 'there',\n",
       " 'for',\n",
       " 'you\"',\n",
       " \"It's\",\n",
       " 'gonna',\n",
       " 'take',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'to',\n",
       " 'drag',\n",
       " 'me',\n",
       " 'away',\n",
       " 'from',\n",
       " 'you',\n",
       " \"There's\",\n",
       " 'nothing',\n",
       " 'that',\n",
       " 'a',\n",
       " 'hundred',\n",
       " 'men',\n",
       " 'or',\n",
       " 'more',\n",
       " 'could',\n",
       " 'ever',\n",
       " 'do',\n",
       " 'I',\n",
       " 'bless',\n",
       " 'the',\n",
       " 'rains',\n",
       " 'down',\n",
       " 'in',\n",
       " 'Africa',\n",
       " 'Gonna',\n",
       " 'take',\n",
       " 'some',\n",
       " 'time',\n",
       " 'to',\n",
       " 'do',\n",
       " 'the',\n",
       " 'things',\n",
       " 'we',\n",
       " 'never',\n",
       " 'had',\n",
       " 'The',\n",
       " 'wild',\n",
       " 'dogs',\n",
       " 'cry',\n",
       " 'out',\n",
       " 'in',\n",
       " 'the',\n",
       " 'night',\n",
       " 'As',\n",
       " 'they',\n",
       " 'grow',\n",
       " 'restless',\n",
       " 'longing',\n",
       " 'for',\n",
       " 'some',\n",
       " 'solitary',\n",
       " 'company',\n",
       " 'I',\n",
       " 'know',\n",
       " 'that',\n",
       " 'I',\n",
       " 'must',\n",
       " 'do',\n",
       " \"what's\",\n",
       " 'right',\n",
       " 'As',\n",
       " 'sure',\n",
       " 'as',\n",
       " 'Kilimanjaro',\n",
       " 'rises',\n",
       " 'like',\n",
       " 'Olympus',\n",
       " 'above',\n",
       " 'the',\n",
       " 'Serengeti',\n",
       " 'I',\n",
       " 'seek',\n",
       " 'to',\n",
       " 'cure',\n",
       " \"what's\",\n",
       " 'deep',\n",
       " 'inside',\n",
       " 'Frightened',\n",
       " 'of',\n",
       " 'this',\n",
       " 'thing',\n",
       " 'that',\n",
       " \"I've\",\n",
       " 'become',\n",
       " \"It's\",\n",
       " 'gonna',\n",
       " 'take',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'to',\n",
       " 'drag',\n",
       " 'me',\n",
       " 'away',\n",
       " 'from',\n",
       " 'you',\n",
       " \"There's\",\n",
       " 'nothing',\n",
       " 'that',\n",
       " 'a',\n",
       " 'hundred',\n",
       " 'men',\n",
       " 'or',\n",
       " 'more',\n",
       " 'could',\n",
       " 'ever',\n",
       " 'do',\n",
       " 'I',\n",
       " 'bless',\n",
       " 'the',\n",
       " 'rains',\n",
       " 'down',\n",
       " 'in',\n",
       " 'Africa',\n",
       " 'Gonna',\n",
       " 'take',\n",
       " 'some',\n",
       " 'time',\n",
       " 'to',\n",
       " 'do',\n",
       " 'the',\n",
       " 'things',\n",
       " 'we',\n",
       " 'never',\n",
       " 'had',\n",
       " 'Hurry',\n",
       " 'boy,',\n",
       " \"she's\",\n",
       " 'waiting',\n",
       " 'there',\n",
       " 'for',\n",
       " 'you',\n",
       " \"It's\",\n",
       " 'gonna',\n",
       " 'take',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'to',\n",
       " 'drag',\n",
       " 'me',\n",
       " 'away',\n",
       " 'from',\n",
       " 'you',\n",
       " \"There's\",\n",
       " 'nothing',\n",
       " 'that',\n",
       " 'a',\n",
       " 'hundred',\n",
       " 'men',\n",
       " 'or',\n",
       " 'more',\n",
       " 'could',\n",
       " 'ever',\n",
       " 'do',\n",
       " 'I',\n",
       " 'bless',\n",
       " 'the',\n",
       " 'rains',\n",
       " 'down',\n",
       " 'in',\n",
       " 'Africa',\n",
       " 'I',\n",
       " 'bless',\n",
       " 'the',\n",
       " 'rains',\n",
       " 'down',\n",
       " 'in',\n",
       " 'Africa',\n",
       " 'I',\n",
       " 'bless',\n",
       " 'the',\n",
       " 'rains',\n",
       " 'down',\n",
       " 'in',\n",
       " 'Africa',\n",
       " 'I',\n",
       " 'bless',\n",
       " 'the',\n",
       " 'rains',\n",
       " 'down',\n",
       " 'in',\n",
       " 'Africa',\n",
       " 'I',\n",
       " 'bless',\n",
       " 'the',\n",
       " 'rains',\n",
       " 'down',\n",
       " 'in',\n",
       " 'Africa',\n",
       " 'Gonna',\n",
       " 'take',\n",
       " 'some',\n",
       " 'time',\n",
       " 'to',\n",
       " 'do',\n",
       " 'the',\n",
       " 'things',\n",
       " 'we',\n",
       " 'never',\n",
       " 'had']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obtainLyrics('Toto', 'Africa')\n",
    "text, indices = replace_words_at_random(nlp, obtainLyrics('Yung Gravy', '1 Thot 2 Thot Red Thot Blue Thot'), 90, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
